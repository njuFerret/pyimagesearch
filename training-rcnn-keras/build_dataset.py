# -----------------------------
#   USAGE
# -----------------------------
# python build_dataset.py

# -----------------------------
#   IMPORTS
# -----------------------------
# Import the necessary packages
from pyimagesearch.iou import compute_iou
from pyimagesearch import config
from bs4 import BeautifulSoup
from imutils import paths
import cv2
import os

# Loop over the output positive and the negative directories
for dirPath in (config.POSITIVE_PATH, config.NEGATIVE_PATH):
    # If the output directory does not exist yet, create it
    if not os.path.exists(dirPath):
        os.makedirs(dirPath)

# Grab all the image paths in the input images directory
imagePaths = list(paths.list_images(config.ORIG_IMAGES))

# Initialize the total number of positive and negative images gathered so far
totalPositive = 0
totalNegative = 0

# Loop over the image paths
for (i, imagePath) in enumerate(imagePaths):
    # Show a progress report
    print("[INFO] Processing image {}/{}...".format(i + 1, len(imagePaths)))
    # Extract the filename from the file path and use it to derive the path to the XML annotation file
    filename = imagePath.split(os.path.sep)[-1]
    filename = filename[:filename.rfind(".")]
    annotationPath = os.path.sep.join([config.ORIG_ANNOTATIONS, "{}.xml".format(filename)])
    # Load the annotation file, build the soup and initialize the list of ground-truth bounding boxes
    contents = open(annotationPath).read()
    soup = BeautifulSoup(contents, "html.parser")
    gtBoxes = []
    # Extract the image dimensions
    w = int(soup.find("width").string)
    h = int(soup.find("height").string)
    # Loop over all 'object' elements
    for o in soup.find_all("object"):
        # Extract the label and bounding box coordinates
        label = o.find("name").string
        xMin = int(o.find("xmin").string)
        yMin = int(o.find("ymin").string)
        xMax = int(o.find("xmax").string)
        yMax = int(o.find("ymax").string)
        # Truncate the bounding box coordinates that may fall outside the boundaries of the image
        xMin = max(0, xMin)
        yMin = max(0, yMin)
        xMax = min(w, xMax)
        yMax = min(h, yMax)
        # Update the list of ground-truth bounding boxes
        gtBoxes.append((xMin, yMin, xMax, yMax))
    # Load the input image from disk
    image = cv2.imread(imagePath)
    # Run selective search on the image and then initialize the list of proposed boxes
    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
    ss.switchToSelectiveSearchFast()
    rects = ss.process()
    proposedRects = []
    # Loop over the rectangles generated by the selective search
    for (x, y, w, h) in rects:
        # Convert the bounding boxes from (x, y, w, h) to (startX, startY, startX, endY)
        proposedRects.append((x, y, x + w, y + h))
    # Initialize the counters used to count the number of positive and negative ROIs saved thus far
    positiveROIs = 0
    negativeROIs = 0
    # Loop over the maximum number of region proposals
    for proposedRect in proposedRects[:config.MAX_PROPOSALS]:
        # Unpack the proposed rectangle bounding box
        (propStartX, propStartY, propEndX, propEndY) = proposedRect
        # Loop over the ground-truth bounding boxes
        for gtBox in gtBoxes:
            # Compute the intersection over the union between the two boxes and unpack the ground-truth bounding box
            iou = compute_iou(gtBox, proposedRect)
            (gtStartX, gtStartY, gtEndX, gtEndY) = gtBox
            # Initialize the ROI and the output path
            roi = None
            outputPath = None
            # Check to see if the IOU is greater than the 70% *and* that the positive count limit has not been hit
            if iou > 0.7 and positiveROIs <= config.MAX_POSITIVE:
                # Extract the ROI and then derive the output path to the positive instance
                roi = image[propStartY:propEndY, propStartX:propEndX]
                filename = "{}.png".format(totalPositive)
                outputPath = os.path.sep.join([config.POSITIVE_PATH, filename])
                # Increment the positive counters
                positiveROIs += 1
                totalPositive += 1
            # Determine if the proposed bounding box falls *within* the ground-truth bounding box
            fullOverlap = propStartX >= gtStartX
            fullOverlap = fullOverlap and propStartY >= gtStartY
            fullOverlap = fullOverlap and propEndX <= gtEndX
            fullOverlap = fullOverlap and propEndY <= gtEndY
            # Check to see if there is not full overlap *and* the IOU is less than 5% *and* the negative count limit has
            # not been hit
            if not fullOverlap and iou < 0.05 and negativeROIs <= config.MAX_NEGATIVE:
                # Extract the ROI and then derive the output path to the negative instance
                roi = image[propStartY:propEndY, propStartX:propEndX]
                filename = "{}.png".format(totalNegative)
                outputPath = os.path.sep.join([config.NEGATIVE_PATH, filename])
                # Increment the negative counters
                negativeROIs += 1
                totalNegative += 1
            # Check to see if both to ROI and the output path are valid
            if roi is not None and outputPath is not None:
                # Resize the ROI to the input dimensions of the CNN that are goint to be used for fine-tuning,
                # then write the ROI to disk
                roi = cv2.resize(roi, config.INPUT_DIMS, interpolation=cv2.INTER_CUBIC)
                cv2.imwrite(outputPath, roi)

